# Importa a biblioteca para criar a interface visual.
import streamlit as st
# Importa a biblioteca para fazer requisi칞칫es web (para falar com nossa API).
import requests
# Importa as ferramentas para rodar tarefas em segundo plano.
import threading
import uvicorn

# A m치gica da conex칚o: importa o objeto 'app_fastapi' do nosso arquivo 'api_server.py'.
from api_server import app_fastapi

# --- L칍GICA PARA INICIAR A API EM SEGUNDO PLANO ---

# Define a fun칞칚o que ser치 executada na tarefa de segundo plano.
def iniciar_api():
    """Esta fun칞칚o simplesmente liga o servidor Uvicorn para nossa API FastAPI."""
    # 'uvicorn.run' 칠 o comando em Python para iniciar o servidor, passando nosso app como alvo.
    uvicorn.run(app_fastapi, host="127.0.0.1", port=8000)

# 'st.session_state' 칠 a mem칩ria do Streamlit. Verificamos se j치 iniciamos a API antes para n칚o fazer de novo.
if "api_thread_started" not in st.session_state:
    # 'threading.Thread' cria o objeto da tarefa que rodar치 em segundo plano.
    # 'target=iniciar_api' diz qual fun칞칚o a tarefa deve executar.
    # 'daemon=True' garante que esta tarefa feche automaticamente quando o app Streamlit for fechado.
    thread = threading.Thread(target=iniciar_api, daemon=True)
    # 'thread.start()' efetivamente inicia a execu칞칚o da tarefa em segundo plano.
    thread.start()
    # 'st.session_state.api_thread_started = True' guarda na mem칩ria que a API j치 foi iniciada.
    st.session_state.api_thread_started = True

# --- INTERFACE DO STREAMLIT (O VISUAL) ---

# 'st.set_page_config' define o t칤tulo e o 칤cone que aparecem na aba do navegador.
st.set_page_config(page_title="Chatbot JP", page_icon="游뱄")

# 'st.title' define o t칤tulo principal da p치gina.
st.title("游뱄 Chatbot Jovem Programador")
# 'st.caption' define um subt칤tulo.
st.caption("Arquitetura Profissional: Streamlit + FastAPI")

# 'if "messages" not in ...' verifica se o hist칩rico de mensagens vis칤veis j치 foi criado na mem칩ria.
if "messages" not in st.session_state:
    # Se n칚o, cria o hist칩rico com a primeira mensagem de boas-vindas do assistente.
    st.session_state.messages = [
        {"role": "assistant", "content": "Ol치! Estou pronto para ajudar com suas d칰vidas sobre o Jovem Programador."}
    ]

# Define a fun칞칚o "mensageira" que conversa com nossa API em segundo plano.
def obter_resposta_da_api(pergunta: str):
    # A URL do nosso pr칩prio servidor FastAPI.
    url_api = "http://127.0.0.1:8000/responder"
    # O corpo da mensagem (payload) que enviaremos, no formato JSON.
    payload = {"texto": pergunta}
    try:
        # 'requests.post' envia a pergunta do front-end (Streamlit) para o back-end (FastAPI).
        response = requests.post(url_api, json=payload, timeout=60)
        # Verifica se a API respondeu com sucesso (c칩digo 200).
        response.raise_for_status()
        # '.json().get(...)' pega a resposta do JSON e retorna o texto.
        return response.json().get("resposta", "Erro na resposta da API.")
    # Captura erros de conex칚o com a API.
    except requests.exceptions.RequestException as e:
        return f"Erro de conex칚o com a API: {e}"

# 'for message in ...:' percorre cada mensagem no hist칩rico da mem칩ria.
for message in st.session_state.messages:
    # 'with st.chat_message(...)' cria um bal칚o de chat para o autor da mensagem.
    with st.chat_message(message["role"]):
        # 'st.markdown' escreve o texto da mensagem dentro do bal칚o.
        st.markdown(message["content"])

# 'if prompt := st.chat_input(...)' cria a caixa de texto e espera o usu치rio digitar.
if prompt := st.chat_input("Qual sua d칰vida?"):
    # 'st.session_state.messages.append(...)' adiciona a nova mensagem do usu치rio ao hist칩rico.
    st.session_state.messages.append({"role": "user", "content": prompt})
    # 'with st.chat_message("user"):' cria um bal칚o de chat para a mensagem do usu치rio.
    with st.chat_message("user"):
        # 'st.markdown(prompt)' escreve a pergunta do usu치rio na tela.
        st.markdown(prompt)
    
    # 'with st.chat_message("assistant"):' cria um bal칚o para a resposta da IA.
    with st.chat_message("assistant"):
        # 'with st.spinner(...)' mostra uma anima칞칚o de "carregando" enquanto esperamos a resposta.
        with st.spinner("Pensando..."):
            # 'resposta = obter_resposta_da_api(prompt)' chama nossa fun칞칚o para obter a resposta da IA.
            resposta = obter_resposta_da_api(prompt)
        # 'st.markdown(resposta)' escreve a resposta final da IA na tela.
        st.markdown(resposta)
    
    # Adiciona a resposta da IA ao hist칩rico para que ela permane칞a na tela.
    st.session_state.messages.append({"role": "assistant", "content": resposta})

    # pra rodar o chatbot - streamlit run app_streamlit.py